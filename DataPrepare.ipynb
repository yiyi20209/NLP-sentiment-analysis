{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["!pip install contractions"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Pq85568M81BT","executionInfo":{"status":"ok","timestamp":1671332296487,"user_tz":300,"elapsed":6096,"user":{"displayName":"linrui ma","userId":"10315317965388359510"}},"outputId":"17516e64-ad1e-45ae-801d-f510137d332f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting contractions\n","  Downloading contractions-0.1.73-py2.py3-none-any.whl (8.7 kB)\n","Collecting textsearch>=0.0.21\n","  Downloading textsearch-0.0.24-py2.py3-none-any.whl (7.6 kB)\n","Collecting anyascii\n","  Downloading anyascii-0.3.1-py3-none-any.whl (287 kB)\n","\u001b[K     |████████████████████████████████| 287 kB 5.2 MB/s \n","\u001b[?25hCollecting pyahocorasick\n","  Downloading pyahocorasick-1.4.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (110 kB)\n","\u001b[K     |████████████████████████████████| 110 kB 44.6 MB/s \n","\u001b[?25hInstalling collected packages: pyahocorasick, anyascii, textsearch, contractions\n","Successfully installed anyascii-0.3.1 contractions-0.1.73 pyahocorasick-1.4.4 textsearch-0.0.24\n"]}]},{"cell_type":"code","source":["import numpy as np \n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","import seaborn as sn\n","import random\n","\n","import matplotlib.pyplot as plt\n","\n","import contractions\n","import nltk\n","import re\n","import string\n","from nltk.corpus import stopwords\n","from nltk.stem import WordNetLemmatizer\n","\n","from sklearn.model_selection import train_test_split\n","\n","from torchtext.data.utils import get_tokenizer\n","from torchtext.vocab import build_vocab_from_iterator\n","from torch.utils.data import DataLoader, TensorDataset\n","from torch.utils.data.dataset import random_split\n","from torchtext.data.functional import to_map_style_dataset\n","from torch import nn\n","import torch\n","import time\n","\n","\n","from tqdm import tqdm\n","import warnings\n","warnings.filterwarnings('ignore')"],"metadata":{"id":"36mZ7QM9KtcE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"S-24-Ut2Kw3F"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["use_gpu = torch.cuda.is_available()\n","print(use_gpu)"],"metadata":{"id":"9QsaF6jJKzg5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_detaset():\n","    train_df = pd.read_csv('/content/drive/MyDrive/IFT6390/kaggle2/train_data.csv')\n","    test_df = pd.read_csv('/content/drive/MyDrive/IFT6390/kaggle2/test_data.csv')\n","    train_result_df = pd.read_csv('/content/drive/MyDrive/IFT6390/kaggle2/train_results.csv')\n","    return train_df, test_df, train_result_df\n","\n","def treat_detaset(train_df, test_df, train_result_df):\n","    train_df= train_df.drop(columns=['id'])\n","    test_df = test_df.drop(columns=['id'])\n","    train_result_df = train_result_df.drop(columns=['id'])\n","\n","    train_result_df.loc[train_result_df['target'] == 'negative'] = 0\n","    train_result_df.loc[train_result_df['target'] == 'neutral'] = 1\n","    train_result_df.loc[train_result_df['target'] == 'positive'] = 2\n","    return train_df, test_df, train_result_df"],"metadata":{"id":"AqOv9UtVK26a"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_df, test_df, train_result_df = get_detaset()\n","train_df, test_df, train_result_df = treat_detaset(train_df, test_df, train_result_df)"],"metadata":{"id":"bTxe5jEDK8ek"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#original text\n","print('positive',train_df[train_result_df.target == 2][0:3])\n","print('neutral',train_df[train_result_df.target == 1][0:3])\n","print('negative',train_df[train_result_df.target == 0][0:3])"],"metadata":{"id":"8G7U7auELEVu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_df.info()"],"metadata":{"id":"EAVxTYz3LGm-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.figure(figsize=(6,5))\n","plt.title(\"Number of records of positive, negative, neutral sentiments\")\n","plot = sn.countplot(x = 'target', data=train_result_df)\n","for p in plot.patches:\n","    plot.annotate(p.get_height(),(p.get_x()+0.1 ,p.get_height()+50))"],"metadata":{"id":"mDgt3WvuLIs6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["nltk.download(\"wordnet\")\n","nltk.download('omw-1.4')\n","lemmatizer = WordNetLemmatizer()\n","\n","def text_preprocessing(df):\n","    #1) Expand contractions in Text Processing\n","    df['reviews_text']=df['text'].apply(lambda x:contractions.fix(x, slang=True))\n","    #2) Lower Case\n","    df['reviews_text'] = df['reviews_text'].str.lower()\n","    #3) Remove punctuations\n","    df['reviews_text'] = df['reviews_text'].apply(lambda x: re.sub('[%s]' % re.escape(string.punctuation), '' , x))\n","    #4) Remove words containing digits\n","    df['reviews_text'] = df['reviews_text'].apply(lambda x: re.sub(r'\\w*\\d\\w*', '', x))\n","    #5) Remove Stopwords\n","    #def remove_stopwords(text):\n","    #    return \" \".join([word for word in str(text).split() if word not in stop_words])\n","    #df['reviews_text'] = df['reviews_text'].apply(lambda x: remove_stopwords(x))\n","    #6) Lemmatization\n","    def lemmatize_words(text):\n","        return \" \".join([lemmatizer.lemmatize(word) for word in text.split()])\n","    df['reviews_text'] = df['reviews_text'].apply(lambda text: lemmatize_words(text))\n","    #7) Remove Extra Spaces\n","    df['reviews_text'] = df['reviews_text'].apply(lambda x: re.sub(' +', ' ', x))\n","    return df"],"metadata":{"id":"Q03fDhKQLPbS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_df_pre = text_preprocessing(train_df)\n","test_df_pre = text_preprocessing(test_df)"],"metadata":{"id":"z5V_np6cLStR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_df_pre.head(5)"],"metadata":{"id":"x6WRkTDvLWqV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["del train_df_pre['text']\n","del test_df_pre['text']"],"metadata":{"id":"QqZ-6UajMZRK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_df_pre.to_csv('train.txt', index=False, header = False)\n","test_df_pre.to_csv('validation.txt', index=False, header = False)\n","\n","train_df_pre['target']=train_result_df['target']\n","train_df_pre['review_text']=train_df_pre['reviews_text']\n","del train_df_pre['reviews_text']\n","\n","train_df_pre[:900000].to_csv('train_ro.txt', index=False, sep='\\t', header = False)\n","train_df_pre[900000:].to_csv('valid_ro.txt', index=False, sep='\\t', header = False)"],"metadata":{"id":"CH9Bm8StMizi"},"execution_count":null,"outputs":[]}]}